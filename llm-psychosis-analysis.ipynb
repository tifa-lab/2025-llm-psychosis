{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875c9aa",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation of large language model chatbot responses to psychotic prompts: numerical ratings of prompt-response pairs: analytic code\n",
    "\n",
    "# 20251109"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a1cbc",
   "metadata": {},
   "source": [
    "# Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e477b08",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(width=800)\n",
    "\n",
    "LIBRARIES <- rlang::quos(\n",
    "    tidyverse,\n",
    "    here,\n",
    "    psych,\n",
    "    skimr,\n",
    "    broom,\n",
    "    broom.mixed,\n",
    "    broom.helpers,\n",
    "    MASS,\n",
    "    brant,\n",
    "    ordinal,\n",
    "    lme4,\n",
    "    lmerTest,\n",
    "    multgee,\n",
    "    gt,\n",
    "    gtsummary,\n",
    "    patchwork)\n",
    "\n",
    "lapply(LIBRARIES, rlang::quo_name) |> \n",
    "    lapply(library, character.only = TRUE) |>\n",
    "    invisible()\n",
    "\n",
    "library(conflicted)\n",
    "\n",
    "conflict_prefer(\"select\", \"dplyr\")\n",
    "conflict_prefer(\"filter\", \"dplyr\")\n",
    "conflict_prefer(\"lmer\", \"lmerTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ee3b8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate tidy summary table for polr output\n",
    "tidy_polr <- function(model) {\n",
    "    tidy_summary_df <- tidy(model) |>\n",
    "        mutate(\n",
    "            p.value = 2 * pnorm(abs(statistic), lower.tail = FALSE),\n",
    "            OR = exp(estimate)\n",
    "        ) |>\n",
    "        # strip thresholds\n",
    "        filter(!grepl(\"\\\\|\", term))\n",
    "\n",
    "    # profile likelihood confidence interval\n",
    "    confidence_interval <- exp(confint(model))\n",
    "\n",
    "    # reshape \n",
    "    if (is.null(dim(confidence_interval))) {\n",
    "        confidence_interval <- matrix(\n",
    "            confidence_interval,\n",
    "            nrow = 1,\n",
    "            dimnames = list(names(coef(model)), c(\"2.5 %\", \"97.5 %\"))\n",
    "        )\n",
    "    }\n",
    "\n",
    "    confidence_interval_df <- tibble(\n",
    "        term = rownames(confidence_interval),\n",
    "        conf.low = confidence_interval[, 1],\n",
    "        conf.high = confidence_interval[, 2]\n",
    "    )\n",
    "\n",
    "    left_join(tidy_summary_df, confidence_interval_df, by = \"term\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18962671",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49d411",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_imported <- \n",
    "    here(\"data\", \"llm_psychosis_numeric_ratings.csv\") |>\n",
    "    read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05be427",
   "metadata": {},
   "source": [
    "# Examine ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf22d05e",
   "metadata": {},
   "source": [
    "## Agreement between primary raters (2 and 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e47d2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_for_kappa <- df_imported |>\n",
    "    select(pair_id, rater, rating) |>\n",
    "    pivot_wider(names_from = rater, values_from = rating)\n",
    "\n",
    "kappa_object <- cohen.kappa(as.matrix(\n",
    "    df_for_kappa |> select(r2, r3)))\n",
    "\n",
    "df_kappa <- kappa_object$confid |>\n",
    "    as_tibble(rownames = \"type\") |>\n",
    "    select(type, estimate, lower, upper)\n",
    "\n",
    "kappa_object\n",
    "df_kappa\n",
    "\n",
    "correlation <- cor.test(\n",
    "    df_for_kappa$r2, df_for_kappa$r3, method = \"spearman\")\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b3ff7",
   "metadata": {},
   "source": [
    "## Consensus rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0468a622",
   "metadata": {},
   "source": [
    "### Median and round down to nearest integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26562a61",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_consensus <- df_imported |>\n",
    "    filter(rater %in% c(\"r2\", \"r3\")) |>\n",
    "    group_by(pair_id) |>\n",
    "    summarize(rating = floor(median(rating)), .groups = \"drop\") |>\n",
    "    mutate(rater = \"consensus\")\n",
    "\n",
    "df_merged <- df_imported |> \n",
    "    left_join(df_consensus, by = c(\"pair_id\", \"rater\", \"rating\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd44ff4f",
   "metadata": {},
   "source": [
    "### Subset comparison of rater 2 & 3 consensus with secondary rater (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b703c99",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_for_kappa_2 <- df_merged |>\n",
    "    select(pair_id, rater, rating) |>\n",
    "    pivot_wider(names_from = rater, values_from = rating)\n",
    "\n",
    "kappa_object_2 <- cohen.kappa(as.matrix(\n",
    "    df_for_kappa_2 |> select(consensus, r1)))\n",
    "\n",
    "df_kappa_2 <- kappa_object_2$confid |>\n",
    "    as_tibble(rownames = \"type\") |>\n",
    "    select(type, estimate, lower, upper)\n",
    "\n",
    "kappa_object_2\n",
    "df_kappa_2\n",
    "\n",
    "correlation_2 <- cor.test(\n",
    "    df_for_kappa_2$r1, df_for_kappa_2$consensus, method = \"spearman\")\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a9685",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7ec87",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_counts <- df_merged |>\n",
    "    mutate(\n",
    "        model = recode(model,\n",
    "            \"chatgpt_free\" = \"\\\"Free\\\"\",\n",
    "            \"chatgpt_4o\" = \"GPT-4o\",\n",
    "            \"chatgpt_5_auto\" = \"GPT-5 Auto\"),\n",
    "        model = factor(model, levels = c(\"GPT-5 Auto\", \"GPT-4o\", \"\\\"Free\\\"\")),\n",
    "        condition = recode(condition,\n",
    "            \"control\" = \"Control\",\n",
    "            \"psychosis\" = \"Psychosis\"),\n",
    "        condition = factor(condition, levels = c(\"Control\", \"Psychosis\")),\n",
    "        rating = factor(\n",
    "            rating, levels = c(0, 1, 2), \n",
    "            labels = c(\"0\", \"1\", \"2\"))\n",
    "    ) |>\n",
    "    count(condition, model, rating, name = \"n\") |>\n",
    "    group_by(condition, model) |>\n",
    "    mutate(prop = n / sum(n)) |>\n",
    "    ungroup()\n",
    "\n",
    "viz_counts <- ggplot(\n",
    "    df_counts, \n",
    "    aes(\n",
    "        y = rating, \n",
    "        x = n, \n",
    "        fill = rating)) +\n",
    "    geom_col(width = 0.25) +\n",
    "    geom_text(\n",
    "        aes(label = n),\n",
    "        position = position_dodge(width = 0.5),\n",
    "        hjust = -0.2,\n",
    "        size = 2\n",
    "    ) +\n",
    "    facet_grid(condition ~ model) +\n",
    "    labs(\n",
    "        y = \"Consensus rating\",\n",
    "        x = \"Number of responses\") +\n",
    "    scale_fill_manual(\n",
    "        values = RColorBrewer::brewer.pal(3, \"Pastel2\"),\n",
    "        labels = c(\n",
    "            \"0\" = \"0: Completely appropriate\",\n",
    "            \"1\" = \"1: Somewhat appropriate\",\n",
    "            \"2\" = \"2: Completely inappropriate\"\n",
    "        )) +\n",
    "    theme_minimal() +\n",
    "    theme(\n",
    "        panel.grid.major.x = element_blank(),\n",
    "        legend.position = \"bottom\"\n",
    "    ) +\n",
    "    guides(fill = guide_legend(title = NULL))\n",
    "\n",
    "viz_counts\n",
    "\n",
    "ggsave(\n",
    "    here(\"output\", \"figure1_counts.png\"), \n",
    "    viz_counts, \n",
    "    width = 7.5, \n",
    "    height = 3, \n",
    "    dpi = 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12e12f",
   "metadata": {},
   "source": [
    "# Primary analysis (across-version proportional odds regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64738d73",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_consensus <- subset(df_merged, rater == \"consensus\")\n",
    "df_consensus$rating  <- ordered(df_consensus$rating)\n",
    "\n",
    "df_consensus$rating <- factor(\n",
    "    df_consensus$rating,\n",
    "    levels = rev(levels(df_consensus$rating)),\n",
    "    ordered = TRUE\n",
    ")\n",
    "\n",
    "df_consensus$model <- as_factor(df_consensus$model)\n",
    "df_consensus$model <- relevel(df_consensus$model, ref = \"chatgpt_free\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5ca9b",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49585cd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model_consensus_all <- ordLORgee(\n",
    "    formula = rating ~ condition * model,\n",
    "    data = df_consensus,\n",
    "    id = prompt_id,\n",
    "    LORstr = \"uniform\",\n",
    "    link = \"logit\",\n",
    ")\n",
    "summary(model_consensus_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366ba83",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f4bc4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_across_versions <- tidy_multgee(model_consensus_all, exponentiate=TRUE)\n",
    "\n",
    "df_across_versions_table <- df_across_versions |> \n",
    "    filter(term != \"beta10\" & term != \"beta20\") |>\n",
    "    mutate(\n",
    "        across(c(estimate, conf.low, conf.high), ~round (.x, 2)),\n",
    "        orci = sprintf(\"%.2f (%.2f–%.2f)\", estimate, conf.low, conf.high)) |>\n",
    "    select(term, orci, p.value)\n",
    "\n",
    "df_across_versions_table\n",
    "\n",
    "df_across_versions_table |> write_csv(\n",
    "    here(\"output\", \"across-versions-table.csv\"))\n",
    "\n",
    "df_across_versions_p <- df_across_versions_table |> \n",
    "    filter(\n",
    "        term == \"conditionpsychosis:modelchatgpt_4o\" | \n",
    "        term == \"conditionpsychosis:modelchatgpt_5_auto\")\n",
    "\n",
    "p.adjust(df_across_versions_p$p.value, method = \"holm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca77707",
   "metadata": {},
   "source": [
    "### Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cddc9e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_across_viz <- df_across_versions |>\n",
    "    filter(term %in% c(\n",
    "        \"conditionpsychosis\",\n",
    "        \"conditionpsychosis:modelchatgpt_4o\",\n",
    "        \"conditionpsychosis:modelchatgpt_5_auto\")) |>\n",
    "    mutate(\n",
    "        effect_type = if_else(\n",
    "            term == \"conditionpsychosis\", \"Main effect\", \"Interaction\"),\n",
    "        term = case_when(\n",
    "            term == \"conditionpsychosis\" ~ \"\\\"Free\\\" baseline\",\n",
    "            term == \"conditionpsychosis:modelchatgpt_4o\" ~ \"GPT-4o relative shift\",\n",
    "            term == \"conditionpsychosis:modelchatgpt_5_auto\" ~ \"GPT-5 Auto relative shift\"))\n",
    "\n",
    "df_across_viz$term <- factor(\n",
    "  df_across_viz$term,\n",
    "  levels = c(\n",
    "    \"GPT-5 Auto relative shift\",\n",
    "    \"GPT-4o relative shift\",\n",
    "    \"\\\"Free\\\" baseline\"\n",
    "  )\n",
    ")\n",
    "\n",
    "across_viz <- ggplot(\n",
    "    df_across_viz, \n",
    "    aes(\n",
    "        y = term, \n",
    "        x = estimate)) +\n",
    "    geom_point(\n",
    "        aes(\n",
    "            color = effect_type)) +\n",
    "    geom_errorbar(\n",
    "        aes(\n",
    "            xmin = conf.low, \n",
    "            xmax = conf.high, \n",
    "            color= effect_type), \n",
    "        width = 0.1) +\n",
    "    scale_color_manual(values = RColorBrewer::brewer.pal(3, \"Paired\"),\n",
    "    name = \"Effect type\") +\n",
    "    geom_vline(xintercept = 1, linetype = \"dotted\") +\n",
    "    scale_x_log10() +\n",
    "    labs(\n",
    "        y = NULL,\n",
    "        x = \"OR\",\n",
    "    ) +\n",
    "    theme_minimal(base_size=10)\n",
    "\n",
    "across_viz \n",
    "\n",
    "ggsave(here(\"output\", \"across-versions-graph.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276501a8",
   "metadata": {},
   "source": [
    "# Secondary analysis (within-version proportional odds regressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15936aa9",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264661ef",
   "metadata": {},
   "source": [
    "#### \"Free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c352b28",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_consensus <- subset(df_merged, rater == \"consensus\")\n",
    "df_consensus$rating <- as_factor(df_consensus$rating)\n",
    "\n",
    "model_free_prop <- polr(\n",
    "    rating ~ condition, \n",
    "    data = subset(\n",
    "        df_consensus, \n",
    "        model == \"chatgpt_free\"), \n",
    "    Hess = TRUE)\n",
    "\n",
    "summary(model_free_prop)\n",
    "brant(model_free_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202e3b60",
   "metadata": {},
   "source": [
    "#### GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e0953",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model_4o_prop <- polr(\n",
    "    rating ~ condition, \n",
    "    data = subset(\n",
    "        df_consensus, \n",
    "        model == \"chatgpt_4o\"), \n",
    "    Hess = TRUE)\n",
    "\n",
    "summary(model_4o_prop)\n",
    "brant(model_4o_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bffb93",
   "metadata": {},
   "source": [
    "#### GPT-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e7ac8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model_5_prop <- polr(\n",
    "    rating ~ condition, \n",
    "    data = subset(df_consensus, model == \"chatgpt_5_auto\"), \n",
    "    Hess = TRUE)\n",
    "\n",
    "summary(model_5_prop)\n",
    "brant(model_5_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a88fe53",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c52ee",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "row_free_prop <- tidy_polr(model_free_prop) |> \n",
    "    mutate(model = \"\\\"Free\\\"\")\n",
    "row_4o_prop <- tidy_polr(model_4o_prop) |>\n",
    "    mutate(model = \"GPT-4o\")\n",
    "row_5_prop <- tidy_polr(model_5_prop) |>\n",
    "    mutate(model = \"GPT-5 Auto\")\n",
    "\n",
    "df_prop <- bind_rows(\n",
    "        row_free_prop,\n",
    "        row_4o_prop,\n",
    "        row_5_prop) |> \n",
    "    select(\n",
    "        model,\n",
    "        term,\n",
    "        estimate,\n",
    "        std.error,\n",
    "        statistic,\n",
    "        OR,\n",
    "        conf.low,\n",
    "        conf.high,\n",
    "        p.value)\n",
    "\n",
    "df_prop \n",
    "\n",
    "df_prop_table <- df_prop |>\n",
    "    mutate(\n",
    "        across(c(OR, conf.low, conf.high), ~ round(.x, 2)),\n",
    "        orci = sprintf(\"%.2f (%.2f–%.2f)\", OR, conf.low, conf.high),\n",
    "        p.value = ifelse(p.value < 0.001, \"<.001\", sprintf(\"%.3f\", p.value))) |>\n",
    "    select(model, orci, p.value) |>\n",
    "    pivot_longer(\n",
    "        cols = c(orci, p.value),\n",
    "        names_to = \"statistic\",\n",
    "        values_to = \"value\") |>\n",
    "    pivot_wider(\n",
    "        names_from = model,\n",
    "        values_from = value)\n",
    "\n",
    "df_prop_table\n",
    "\n",
    "df_prop_table |> write_csv(here(\"output\", \"within-version-table.csv\"))\n",
    "\n",
    "p.adjust(df_prop$p.value, method = \"holm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f7c61",
   "metadata": {},
   "source": [
    "### Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e303a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_prop_viz <- df_prop\n",
    "\n",
    "df_prop_viz$model <- factor(\n",
    "    df_prop_viz$model, \n",
    "    ordered = TRUE,\n",
    "    levels = c(\"GPT-5 Auto\",\"GPT-4o\", \"\\\"Free\\\"\")\n",
    ")\n",
    "\n",
    "within_viz <- ggplot(\n",
    "    df_prop_viz, \n",
    "    aes(\n",
    "        y = model, \n",
    "        x = OR)) +\n",
    "    geom_point() +\n",
    "    geom_errorbar(\n",
    "        aes(\n",
    "            xmin = conf.low, \n",
    "            xmax = conf.high), \n",
    "            width = 0.1) +\n",
    "    geom_vline(xintercept = 1, linetype = \"dotted\") +\n",
    "    scale_x_log10() +\n",
    "    labs(\n",
    "        y = NULL,\n",
    "        x = \"OR\") +\n",
    "    theme_minimal(base_size = 10)\n",
    "\n",
    "within_viz \n",
    "\n",
    "ggsave(here(\"output\", \"within-version-graph.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0559a1",
   "metadata": {},
   "source": [
    "# Linear version of primary analysis (across-version linear regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5edcca",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561e3cb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_consensus$rating  <- as.numeric(as.character(df_consensus$rating))\n",
    "df_consensus$model <- as_factor(df_consensus$model)\n",
    "df_consensus$model <- relevel(df_consensus$model, ref = \"chatgpt_free\")\n",
    "\n",
    "model_consensus_all_mixed <- lmer(\n",
    "    rating ~ condition * model + (1 | prompt_id) , \n",
    "    data = df_consensus)\n",
    "\n",
    "summary(model_consensus_all_mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16be7c",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a73eca",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_linear_across <- tidy(model_consensus_all_mixed, conf.int = TRUE)\n",
    "df_linear_across\n",
    "\n",
    "df_linear_across_table <- df_linear_across |>\n",
    "    filter(term != \"(Intercept)\" & term != \"sd__(Intercept)\" & term != \"sd__Observation\") |>\n",
    "    mutate(\n",
    "        across(c(estimate, conf.low, conf.high), ~round (.x, 2)),\n",
    "        eci = sprintf(\"%.2f (%.2f–%.2f)\", estimate, conf.low, conf.high)) |>\n",
    "    select(term, eci, p.value)\n",
    "    \n",
    "df_linear_across_table |> write_csv(\n",
    "    here(\"output\", \"across-versions-linear-table.csv\"))\n",
    "\n",
    "df_linear_across_table_p <- df_linear_across_table |> filter(\n",
    "    term == \"conditionpsychosis:modelchatgpt_4o\" | \n",
    "    term == \"conditionpsychosis:modelchatgpt_5_auto\")\n",
    "\n",
    "p.adjust(df_linear_across_table_p$p.value, method = \"holm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c98cbc",
   "metadata": {},
   "source": [
    "### Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd19551",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_linear_across_viz <- df_linear_across\n",
    "\n",
    "df_linear_across_viz <- df_linear_across_viz |>\n",
    "    filter(term %in% c(\n",
    "        \"conditionpsychosis\",\n",
    "        \"conditionpsychosis:modelchatgpt_4o\",\n",
    "        \"conditionpsychosis:modelchatgpt_5_auto\")) |>\n",
    "    mutate(\n",
    "        effect_type = if_else(\n",
    "            term == \"conditionpsychosis\", \"Main effect\", \"Interaction\"),\n",
    "        term = case_when(\n",
    "            term == \"conditionpsychosis\" ~ \"\\\"Free\\\" baseline\",\n",
    "            term == \"conditionpsychosis:modelchatgpt_4o\" ~ \"GPT-4o relative shift\",\n",
    "            term == \"conditionpsychosis:modelchatgpt_5_auto\" ~ \"GPT-5 Auto relative shift\"))\n",
    "\n",
    "df_linear_across_viz$term <- factor(\n",
    "  df_linear_across_viz$term,\n",
    "  levels = c(\n",
    "    \"GPT-5 Auto relative shift\",\n",
    "    \"GPT-4o relative shift\",\n",
    "    \"\\\"Free\\\" baseline\"\n",
    "  )\n",
    ")\n",
    "\n",
    "linear_across_viz <- ggplot(df_linear_across_viz, aes(y = term, x = estimate)) +\n",
    "    geom_point(aes(color = effect_type)) +\n",
    "    geom_errorbar(aes(xmin = conf.low, xmax = conf.high, color= effect_type), width = 0.1) +\n",
    "    geom_vline(xintercept = 0, linetype = \"dotted\") +\n",
    "    scale_color_manual(values = RColorBrewer::brewer.pal(3, \"Paired\"),\n",
    "    name = \"Effect type\") +\n",
    "    labs(\n",
    "        y = NULL,\n",
    "        x = expression(italic(B)~\"\")) +\n",
    "    theme_minimal()\n",
    "\n",
    "linear_across_viz\n",
    "\n",
    "ggsave(here(\"output\", \"across-versions-linear-graph.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6361c",
   "metadata": {},
   "source": [
    "# Linear version of secondary analysis (within-version linear regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368bdd65",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4203d",
   "metadata": {},
   "source": [
    "#### ChatGPT free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2116d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model_consensus_free_linear <- lm(\n",
    "    rating ~ condition, \n",
    "    data = subset(df_consensus, model == \"chatgpt_free\"))\n",
    "    \n",
    "summary(model_consensus_free_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fa5a4",
   "metadata": {},
   "source": [
    "#### ChatGPT 4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b80aa",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model_consensus_4o_linear <- lm(\n",
    "    rating ~ condition, \n",
    "    data = subset(df_consensus, model == \"chatgpt_4o\"))\n",
    "    \n",
    "summary(model_consensus_4o_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea60168",
   "metadata": {},
   "source": [
    "#### ChatGPT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080a10e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model_consensus_5_linear <- lm(\n",
    "    rating ~ condition, \n",
    "    data = subset(df_consensus, model == \"chatgpt_5_auto\"))\n",
    "    \n",
    "summary(model_consensus_5_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46552c",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d5d64",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "row_free_linear <- tidy(model_consensus_free_linear, conf.int = TRUE) |>\n",
    "    filter(term != \"(Intercept)\") |>\n",
    "    mutate(model = \"\\\"Free\\\"\")\n",
    "\n",
    "row_4o_linear <- tidy(model_consensus_4o_linear, conf.int = TRUE) |>\n",
    "    filter(term != \"(Intercept)\") |>\n",
    "    mutate(model = \"GPT-4o\")\n",
    "\n",
    "row_5_linear <- tidy(model_consensus_5_linear, conf.int = TRUE) |>\n",
    "    filter(term != \"(Intercept)\") |>\n",
    "    mutate(model = \"GPT-5 Auto\")\n",
    "\n",
    "df_linear <- bind_rows(\n",
    "        row_free_linear,\n",
    "        row_4o_linear,\n",
    "        row_5_linear) |> \n",
    "    select(\n",
    "        model,\n",
    "        term,\n",
    "        estimate,\n",
    "        std.error,\n",
    "        statistic,\n",
    "        estimate,\n",
    "        conf.low,\n",
    "        conf.high,\n",
    "        p.value)\n",
    "\n",
    "df_linear \n",
    "\n",
    "df_linear_table <- df_linear |>\n",
    "    mutate(\n",
    "        across(c(estimate, conf.low, conf.high), ~ round(.x, 2)),\n",
    "        eci = sprintf(\"%.2f (%.2f–%.2f)\", estimate, conf.low, conf.high),\n",
    "        p.value = ifelse(p.value < 0.001, \"<.001\", sprintf(\"%.3f\", p.value))) |>\n",
    "    select(model, eci, p.value) |>\n",
    "    pivot_longer(\n",
    "        cols = c(eci, p.value),\n",
    "        names_to = \"statistic\",\n",
    "        values_to = \"value\") |>\n",
    "    pivot_wider(\n",
    "        names_from = model,\n",
    "        values_from = value)\n",
    "\n",
    "df_linear_table\n",
    "\n",
    "df_linear_table |> write_csv(here(\"output\", \"within-version-linear-table.csv\"))\n",
    "\n",
    "p.adjust(df_linear$p.value, method = \"holm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1ca4e",
   "metadata": {},
   "source": [
    "### Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847fe925",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_linear_viz <- df_linear\n",
    "\n",
    "df_linear_viz$model <- df_linear_viz$model <- factor(\n",
    "    df_linear_viz$model, \n",
    "    ordered = TRUE,\n",
    "    levels = c(\"GPT-5 Auto\",\"GPT-4o\", \"\\\"Free\\\"\")\n",
    ")\n",
    "\n",
    "linear_within_viz <- ggplot(\n",
    "    df_linear_viz, \n",
    "    aes(\n",
    "        y = model, \n",
    "        x = estimate)) +\n",
    "    geom_point() +\n",
    "    geom_errorbar(\n",
    "        aes(\n",
    "            xmin = conf.low, \n",
    "            xmax = conf.high), \n",
    "            width = 0.1) +\n",
    "    geom_vline(\n",
    "        xintercept = 0, \n",
    "        linetype = \"dotted\") +\n",
    "    labs(\n",
    "        y = NULL,\n",
    "        x = expression(italic(B)~\"\")) +\n",
    "    theme_minimal(base_size=10)\n",
    "\n",
    "linear_within_viz\n",
    "\n",
    "ggsave(here(\"output\", \"within-version-linear-graph.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3f007",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p_combined <- across_viz + within_viz + linear_across_viz + linear_within_viz +\n",
    "       plot_layout(ncol = 2) + \n",
    "       plot_annotation(tag_levels = \"a\")\n",
    "\n",
    "ggsave(here(\"output\",\"combined_figure.png\"),\n",
    "       p_combined,\n",
    "       width = 11,\n",
    "       height = 6,\n",
    "       units = \"in\",\n",
    "       dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b119702",
   "metadata": {},
   "source": [
    "# Exploratory analysis of positive symptom domains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb4759e",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7aaebd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_domains <- df_consensus |> \n",
    "    # dichotomize rating (since we are underpowered here)\n",
    "    mutate(inappropriate = if_else(rating > 0, 1, 0))\n",
    "\n",
    "df_domains$prompt_id <- as_factor(df_domains$prompt_id)\n",
    "df_domains$positive_symptom_domain <- as_factor(df_domains$positive_symptom_domain)\n",
    "\n",
    "df_domains$positive_symptom_domain <- relevel(\n",
    "    df_domains$positive_symptom_domain,\n",
    "    ref = \"unusual_thought_content_delusions\"\n",
    ")\n",
    "\n",
    "model_consensus_domains <- glmer(\n",
    "    inappropriate ~ positive_symptom_domain + (1 | prompt_id), \n",
    "    data = subset(df_domains, condition == \"psychosis\"),\n",
    "    family = binomial)\n",
    "\n",
    "summary(model_consensus_domains)\n",
    "\n",
    "df_domains_model <- tidy(\n",
    "    model_consensus_domains, \n",
    "    conf.int = TRUE, \n",
    "    exponentiate = TRUE)\n",
    "\n",
    "df_domains_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203a43e",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffe761",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_domains_model_table <- df_domains_model |>\n",
    "    filter(effect != \"ran_pars\" & term != \"(Intercept)\") |>\n",
    "    mutate(\n",
    "        across(c(estimate, conf.low, conf.high), ~round (.x, 2)),\n",
    "        eci = sprintf(\"%.2f (%.2f–%.2f)\", estimate, conf.low, conf.high)) |>\n",
    "    select(c(term, eci, p.value))\n",
    "\n",
    "df_domains_model_table\n",
    "\n",
    "df_domains_model_table |> write_csv(here(\"output\",\"exploratory_domains.csv\"))\n",
    "\n",
    "p.adjust(df_domains_model_table$p.value, method = \"holm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
